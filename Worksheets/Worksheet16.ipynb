{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 16 Group Worksheet\n",
    "Oct 29, 2025\n",
    "\n",
    "If you're working on CoCalc, it's good to rename your notebook with a fun group name and to include your names below so that you can easily find it later for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Group members:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1. Is Gandalf's Sparkle spell operating at a frequency of 0.4 Hz?\n",
    "Gandalf is worried that his wand has been misbehaving and comes to you for help. He says that when he casts his \"Sparkle\" spell, the wand should emit an energy beam with a time dependence of $e^{\\sin(2\\pi f t)}$, where the frequency, $f$, is expected to be 0.4 Hz. You make some measurements with a detector that has an offset, so you expect your measurements to follow the model,\n",
    "\n",
    "$$a e^{\\sin(2\\pi f t)}+b $$. \n",
    "\n",
    "The data are given below with x = time, y = power measurement.\n",
    "\n",
    "Use `scipy.optimize.curve_fit` to fit the data to the expected model to **find the frequency, with uncertainty,** of Gandalf's wand. Use $a$, $b$, and $f$ as adjustable parameters. After you have found the best-fit model, make a plot with the data as points and the fitted expression as a solid line. \n",
    "\n",
    "**Important!** Reasonable initial guesses for the parameters will be ***critical*** in getting this fit to work. You will likely find that it is easiest to plot the predicted function using your initial guesses with the data to fine-tune your initial guesses before performing the actual fit. \n",
    "\n",
    "**Compare your fitted frequency for the Sparkle spell to the expected frequency of 0.4 Hz.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "\n",
    "x = np.array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,\n",
    "       1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2, 2.3, 2.4, 2.5,\n",
    "       2.6, 2.7, 2.8, 2.9, 3. , 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8,\n",
    "       3.9, 4. , 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5. , 5.1,\n",
    "       5.2, 5.3, 5.4, 5.5, 5.6])\n",
    "y = np.array([ 2.61994972,  1.52344119,  2.66695642,  2.63510806,  3.60031101,\n",
    "        2.57370534,  2.89069675,  0.79754501,  1.74746723,  1.31627036,\n",
    "        1.20939655,  0.74268696,  0.85516989, -0.06723689,  1.14169057,\n",
    "        0.86339867,  1.1910958 ,  1.62603995,  2.00552346,  2.55784377,\n",
    "        4.00631938,  3.2216312 ,  3.86061875,  2.71320536,  3.00682441,\n",
    "        2.11610599,  0.52543879,  1.21171504,  0.59027355,  0.96636379,\n",
    "        0.80961938,  0.79622451,  0.3739691 ,  1.13397128,  1.66157585,\n",
    "        2.66665366,  1.50829326,  3.25834323,  4.05615499,  3.71286446,\n",
    "        3.24564437,  1.63026018,  3.79772738,  1.31377024,  1.32611747,\n",
    "       -0.10359754,  0.78150486,  0.02489367,  0.41951861,  0.71277322,\n",
    "        0.96786975,  1.54895206,  1.2514267 ,  2.55330234,  3.59849077,\n",
    "        3.50118096,  3.62727696])\n",
    "dy = np.array([0.6810214 , 0.62563064, 0.01070687, 0.85023779, 0.2210469 ,\n",
    "       0.44244275, 0.22754862, 0.75183376, 0.03598818, 0.06791264,\n",
    "       0.32464543, 0.55078786, 1.10090497, 0.92183415, 0.57892601,\n",
    "       0.06316342, 0.51616619, 0.11769887, 0.0520352 , 0.3879953 ,\n",
    "       1.35164277, 0.50750878, 0.83302854, 0.51599122, 0.73272766,\n",
    "       0.57767488, 0.32889288, 0.21739519, 0.77054122, 0.5742275 ,\n",
    "       0.10493464, 0.50552201, 0.35216945, 0.13766787, 0.41665939,\n",
    "       0.63508184, 0.91030971, 0.0750346 , 0.5638139 , 0.65856472,\n",
    "       0.56797019, 0.48034953, 1.23783708, 0.04598866, 0.49142786,\n",
    "       0.51589079, 0.19031348, 0.49042393, 0.7350357 , 0.38123459,\n",
    "       0.94595124, 0.05787982, 0.67835271, 0.85777096, 0.71185902,\n",
    "       0.12812123, 0.14148552])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution part 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution part 3\n",
    "\n",
    "# Now that we have some reasonable initial guesses, let's peform the fit\n",
    "params, cov = optimize.curve_fit(func, x, y, p0=[1.1, 0.3, 0.59])\n",
    "plt.errorbar(x,y,dy, fmt='ro')\n",
    "yfit = func(x,*params)\n",
    "plt.plot(x, yfit,\"b-\")\n",
    "plt.title(\"Wand test\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Wand Power (arbitrary units)\")\n",
    "print(f\"The frequency is: {params[2]:.4f} Hz\")\n",
    "print(f\"The uncertainty in frequency is: {np.sqrt(np.diag(cov))[2]:.4f} Hz\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Simulate and fit radiation shielding data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is based on a Physics 119 experiment, where you are seeking to measure the attentuation coefficient of some shielding with respect to a specific source of radiation. \n",
    "\n",
    "A simple, but effective first-order model for the behaviour of the shielding is that the radiation count rate observed in your detector can be modelled as\n",
    "\n",
    "$$R(x) = R_0 e^{-Œºx} + R_b,$$\n",
    "\n",
    "where \n",
    "\n",
    "* $R_0$ is the radiation count-rate observed by the detector when the radiation source is placed at a specific location/distance from the detector\n",
    "* $x$ is the thickness of the shielding in between the source and detector, where this shielding has an attenuation coefficient $\\mu$,\n",
    "* $R_b$ is the background / environmental radiation count-rate, which is negligibly unaffected by this shielding, and \n",
    "* $R(x)$ is the count-rate measured by the detector when a thickness $x$ of shielding is present, but also includes contributions due to background/environmental radiation. \n",
    "\n",
    "In Part 1 of this task you are going to build a simulation to produce the data---you are going to run the experiment. In part 2 of this task you are going to analyze the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Task 2.1: Simulate radiation shielding data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simulation of an experiment to measure the attenuation coefficent of the shielding, $\\mu$, with the following parameters and constraints.\n",
    "\n",
    "1. When generating the simulated data, use the following parameters.<br>\n",
    "  * $R_0 = 20\\mbox{ counts/s}$,\n",
    "  * $R_b = 0.18\\mbox{ counts/s}$, and\n",
    "  * $\\mu = 0.5\\mbox{ mm}^{-1}$.<br><br>\n",
    "1. Observations of radioactive decay rates can be modelled using a Poisson distribution based on the expected number of counts, $\\lambda$, for the time over which you are measuring ($R(x) \\times t$ for your data). \n",
    "  * For example, if you are modelling a one hour (3600 seconds) measurement of the background count-rate, the expected number of counts that you would measure would be $\\lambda = 0.18\\mbox{ counts/s} \\times 3600 \\mbox {s} = 648 \\mbox{ counts}$. The number of counts that you would actually measure (i.e. your simulated measurement) in one hour would follow a Poisson distribution with $\\lambda = 648$. For reference, values of $\\lambda = 20$ or higher a Poisson distribution behaves approximately like a Gaussian distribution with a standard deviation equal to the square root of $\\lambda$. We want you to model these data using a Poisson distribution, but are discussing this Gaussian-like behaviour to help you understand why you need only the one parameter $\\lambda$ to model both the approximate mean and variation when using a Poisson distribution. <br><br>\n",
    "1. Use your simulation to collect data at various thicknesses of shielding, $x$. Your cumulative data collection time across all of your different thicknesses, $x$, should be 30 minutes. This means that you will want to balance how many different thicknesses at which you want to measure with how long you want to measure at each of these thicknesses. To get the best possible estimate of $\\mu$, it is best to included some measurements at a few different thicknesses where you expect the count-rate to be dominated by background radiation (meaning at thicknesses where the contribution of the exponential term is very small because the shielding has blocked most of the radiation from the source). \n",
    "\n",
    "**Produce a plot of your measured/simulated count-rates as a function of shielding thickness.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to produce simulated data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to plot simulated data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Task 2.2: Analyze simulated data---what is your experimentally determined attenuation coefficient,* ùúá?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The purpose of this task is to look more carefully at fitting parameters and fitting parameter uncertainties. Given that we know the \"true\" values of what was used to simulate the data, we have an excellent mechanism to compare our fitting parameters, within uncertainty, with the expected values.**\n",
    "\n",
    "Use `optimize.curve_fit` to fit the model to your simulated data and then generate a plot of your data (with uncertainties) and the fitted model. Additionally, extract $mu$ and its uncertainty from the fit parameters. If you are feeling ambitous, you should also generate a graph of residuals vs $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
